{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7mPxJhPD6efIJ5pC/cIqf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksemina61/task1semestr/blob/main/Homework_CL3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1w_zUliU4Ql"
      },
      "outputs": [],
      "source": [
        "# Контрольная работа по компьютерной лингвистике\n",
        "# задание №1\n",
        "2) Что такое бейзлайн, пайплайн, SOTA? Приведите примеры.\n",
        "Бейзлайн - простая модель (базовая линия), используется для для оценки и сравнения производительности более сложных моделей.\n",
        "В бейзлайне распространенные базовые модели включают линейную регрессию при прогнозировании непрерывных значений, логистическую регрессию при классификации структурированных данных.\n",
        "Пример бейзлайна: классификации электронных писем на спам и не спам.Этот базовый подход может быть использован для сравнения с более сложными алгоритмами классификации (например, Наивный Байес).\n",
        "Пайплайн - это последовательность шагов или этапов, которые выполняются для решения конкретной задачи. Например, отбор признаков, выбор модели, обучение модели.\n",
        "Пример пайплайна: распознавание изображений, то есть загрузка и предобработка изображений, выделение признаков (например, черты лица), обучение на этих признаках.\n",
        "SOTA - алгоритм, который предоставляет наилучшее решение или результат в определенной области или задаче.\n",
        "Пример SOTA: GPT-3 - это модель, обучаемая на больших объемах текстовых данных для генерации текста с высоким качеством.\n",
        "3) Какие элементы имплементации регулярного языка PCRE не являются собственно элементами грамматики регулярного языка по классификации Хомского?\n",
        "PCRE — библиотека, реализующая работу регулярных выражений. Не являются обратными элементами:\n",
        "- Обратные ссылки, так как PCRE позволяет использовать обратные ссылки на группы в регулярном выражении, что позволяет ссылаться на уже найденные части строки, а эта функция не входит в классическую грамматику регулярного языка.\n",
        "- Рекурсивные выражения, так как PCRE позволяет использовать рекурсию в регулярных выражениях, что также не является элементом классической грамматики регулярного языка.\n",
        "4) Что такое языковая модель?\n",
        "Языковая модель - это модель, генерерующая текст на человеческом языке или же можно сказать, что языковая модель - это алгоритм, который позволяет вычислить вероятность появления в предложении того или иного слова.Языковые модели обучаются на больших объемах данных, это могут быть, например, книги, сайты или же статьи.\n",
        "Очевидно, что языковая модель также может предсказывать вероятность пропущенного или следующего токена. Если я правильно поняла, то в языковые модели заложено много параметров. Параметры - это что-то вроде переменных, присущих модели и меняющихся в процессе обучения. Благодаря большому числу параметров языковые модели способны генерировать, прогнозировать, переводить и распознавать контент.\n",
        "5) Какие типы языковых моделей вы знаете?\n",
        "Существует несколько типов языковых моделей:\n",
        "- Статистические (Statistical language models). Пример: N-gram models\n",
        "- Нейронные  (neural language models). Пример: word2vec, GloVe, fasttext\n",
        "- Предварительно обученные языковые модели (Pre-trained language models). Пример: ELMo, BART, GPT-1,2\n",
        "- Большие языковые модели (Large language moels). Пример: GPT-3, 4, PaLM.\n",
        "6) Чем задача классификации отличается от задачи кластеризации?\n",
        "При классификации в машинном обучении объектам присваиваются категории на основе их признаков или характеристик, то есть модель обучается на размеченных данных, каждый объект имеет метку класса.\n",
        "При кластеризации объекты деляться на группы или же кластеры на основе схожести, при этом метки классов могут быть неизвестными заранее."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# задача №2\n",
        "# Метрика - показатель качества работа алгоритма анализа данных. Иначе говоря, насколько качественно работает тот или иной алгоритм. Принимает на вход правильные ответы и ответы алгоритма.\n",
        "# Для того чтобы оценить качество морфологического анализа, мне нужно учитывать лемматизацию, части речи и морфологические характеристики (например, падеж).\n",
        "# В лемматизации нужно сравнить исходные леммы с предсказаннами, используя метрику точности, можно выразить долю правильно лемматизированных слов от их общего числа.\n",
        "# Точность или (Accuracy) вычисляются по формуле: Accuracy = (Количество правильно предсказанных лемм)/(Общее количество слов).\n",
        "# Если предписывать части речи, то лучше воспользоваться метрикой precision (точность), тогда формула будет следующая:  Precision = (True Positives)/(True Positives + False Positives)\n",
        "# Точность (Precision) нужнв для того, чтобы рассмотреть долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом.\n",
        "# Accuracy - это число верно угаданных меток.\n",
        "# Для оценки качества падежа можно использовать аналогичные метрики, но так как precision уже взяла за части речи, то использую полноту (recall)\n",
        "# Полнота (Recall) - мы рассматриваем долю правильно найденных положительных объектов среди всех объектов положительного класса.\n",
        "# Формула полноты (Recall) = True positive/True positive + False negative.\n",
        "# Общая F-мера (F1), объединяет общую точность и общую полноту. Формула: F1 = 2  ((P  R) / (P + R)), где P и R - точность и полнота."
      ],
      "metadata": {
        "id": "gVcpLTJAejpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Во 2 задаче использую уже существующие метрики из библиотеки sklearn.metrics, такие как accuracy_score, precision_score, recall_score и f1_score\n",
        "# Рассмотрю леммантизацию, части речи и падеж\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score #  с помощью этой библиотеки импортирую метрику оценки качества\n",
        "y_true_lemmatization = ['going', 'stopping', 'best', 'run', 'cats'] # создаю переменную истинных результатов для лемм, возьму в качестве примера эти слова\n",
        "y_pred_lemmatization = ['go', 'stop', 'good', 'run', 'cat'] # создаю переменную для предсказанных результатов\n",
        "y_true_pos = ['ADJ', 'ADJ', 'ADJ', 'VERB', 'NOUN']  # то же самое делаю с частями речи\n",
        "y_pred_pos = ['VERB', 'VERB', 'ADJ', 'VERB', 'NOUN']\n",
        "y_true_case = ['Nom', 'Acc', 'Gen', 'Nom', 'Nom']\n",
        "y_pred_case = ['Nom', 'Acc', 'Gen', 'Nom', 'Nom']\n",
        "accuracy_lemmatization = accuracy_score(y_true_lemmatization, y_pred_lemmatization) # оценка качества лемантизации\n",
        "precision_pos = precision_score(y_true_pos, y_pred_pos, average=None) # average=None указывает, что мы хотим получить точность для каждой отдельной категории части речи\n",
        "recall_pos = recall_score(y_true_pos, y_pred_pos, average=None) # оцениваю качество припиывания частей речи\n",
        "f1_pos = f1_score(y_true_pos, y_pred_pos, average=None)\n",
        "precision_case = precision_score(y_true_case, y_pred_case, average=None) # оцениваю качество приписывания падежей\n",
        "recall_case = recall_score(y_true_case, y_pred_case, average=None)\n",
        "f1_case = f1_score(y_true_case, y_pred_case, average=None)\n",
        "# Теперь нужно создать DataFrame для того чтобы увидеть результат, создам словарь\n",
        "# В DataFrame из словаря data с использованием библиотеки Pandas и будут содержаться результаты оценки качества работы морф анализа\n",
        "data = {'Metric': ['Lemmatization accuracy', 'Noun precision', 'Verb precision', 'Adjective precision',\n",
        "                   'Noun recall', 'Verb recall', 'Adjective recall', 'Case precision', 'Case recall', 'Case F1'],\n",
        "        'Value': [accuracy_lemmatization,  precision_pos[0], precision_pos[1], precision_pos[2], recall_pos[0], recall_pos[1], recall_pos[2],\n",
        "              precision_case[0], recall_case[0], f1_case[0]]\n",
        "        }\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVIvQWJBqzJA",
        "outputId": "791bd571-49f6-40ad-d576-4b815886180f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Metric     Value\n",
            "0  Lemmatization accuracy  0.200000\n",
            "1          Noun precision  1.000000\n",
            "2          Verb precision  1.000000\n",
            "3     Adjective precision  0.333333\n",
            "4             Noun recall  0.333333\n",
            "5             Verb recall  1.000000\n",
            "6        Adjective recall  1.000000\n",
            "7          Case precision  1.000000\n",
            "8             Case recall  1.000000\n",
            "9                 Case F1  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install natasha\n",
        "! pip install navec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf0tQTIQGpiJ",
        "outputId": "c5002fa5-2e3a-4eda-8cfa-92bfd30feac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: natasha in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.9.1)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.10.0)\n",
            "Requirement already satisfied: slovnet>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.6.0)\n",
            "Requirement already satisfied: yargy>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.16.0)\n",
            "Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.9.0)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.10/dist-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from navec>=0.9.0->natasha) (1.23.5)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: navec in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from navec) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Задача 4 из прошлого дз по КЛ, пользовалась информацией, которая предоставлена здесь : https://nbviewer.org/github/natasha/natasha/blob/master/docs.ipynb\n",
        "from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsSyntaxParser,\n",
        "    NewsNERTagger,\n",
        "    PER,\n",
        "    LOC,\n",
        "    NamesExtractor,\n",
        "    DatesExtractor,\n",
        "    AddrExtractor,\n",
        "    Doc)\n",
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "syntax_parser = NewsSyntaxParser(emb)\n",
        "ner_tagger = NewsNERTagger(emb)\n",
        "names_extractor = NamesExtractor(morph_vocab)\n",
        "dates_extractor = DatesExtractor(morph_vocab)\n",
        "addr_extractor = AddrExtractor(morph_vocab)\n",
        "with open('news_text.txt', 'r', encoding='utf-8') as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "yZVb3bLRIsHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = Doc(text) # вот тут наташа должна распознать именованные сущности\n",
        "doc.segment(segmenter)\n",
        "doc.tag_morph(morph_tagger) # это я пыталась экспериментировать с наташей, можно было не добавлять segmentation, но я пыталась разобраться лучше в ее функциях\n",
        "doc.tag_ner(ner_tagger)\n",
        "doc.ner.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyW0ysR2QT3M",
        "outputId": "deea03c3-60f1-4937-d266-5810a99f3796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Заголовок: Планы команды \"Стрела\" на шестой этап гонок \"Гранд При\" \n",
            "                          ORG───                                   \n",
            "раскрыты\n",
            "Страница 1:\n",
            "На днях, команда \"Стрела\" официально объявила свои планы на \n",
            "                  ORG───                                    \n",
            "предстоящий шестой этап гонок \"Гранд При\". Главный инженер команды - \n",
            "Джон Смит - поделился деталями планов на пресс-конференции, которая \n",
            "PER──────                                                           \n",
            "проходила в спортивном комплексе \"АвтоТрек\" в городе Спрингфилд.\n",
            "                                  ORG─────           LOC─────── \n",
            "Гонка \"Гранд При\" уже стала одним из самых ожидаемых событий года для \n",
            "любителей автоспорта. В этом сезоне нас ожидает действительно \n",
            "закрученная борьба между профессиональными командами. Команда \"Стрела\"\n",
            "                                                               ORG─── \n",
            " не является исключением и надеется занять лидирующие позиции в общем \n",
            "зачёте.\n",
            "Новые изменения в машине, разработанные командой \"Стрела\", вызывают \n",
            "                                                  ORG───            \n",
            "бурное интерес в автоспортивном сообществе. Начиная с шестого этапа, \n",
            "инженеры команды внесли ряд улучшений в двигатель, подвеску и \n",
            "аэродинамику машины, что должно обеспечить лучшую проходимость трассы \n",
            "и повысить градус соперничества между гонщиками.\n",
            "Один из ключевых моментов плана команды \"Стрела\" - подписать нового \n",
            "                                         ORG───                     \n",
            "опытного гонщика. После долгих переговоров, они смогли пригласить Марк\n",
            "                                                                  PER─\n",
            " Робинсона, бывшего пилота команды \"Блиц\". Это вызвало польщение и \n",
            "──────────                          ORG─                           \n",
            "восторг среди поклонников автоспорта, так как Марк известен своими \n",
            "                                              PER─                 \n",
            "успешными выступлениями на прошлых сезонах.\n",
            "Страница 2:\n",
            "Помимо нового гонщика, команда \"Стрела\" активно работает над \n",
            "                                ORG───                       \n",
            "улучшением всего технического обслуживания. Они наняли известного \n",
            "инженера Дэвида Харпера, ранее работавшего в команде \"Молния\", чтобы \n",
            "         PER───────────                               ORG───         \n",
            "привнести свои неповторимые знания и опыт.\n",
            "Команда также будет менять тактику во время гонок, что ожидается \n",
            "помочь в борьбе за победу. Согласно секретной информации, которая \n",
            "просочилась в прессу, команда \"Стрела\" будет стремиться к \n",
            "                               ORG───                     \n",
            "предпочтительной позиции на стартовой решетке, чтобы иметь \n",
            "преимущество при первом повороте на трассе.\n",
            "Все глаза автоспортивного мира будут обращены на команду \"Стрела\" в \n",
            "                                                          ORG───    \n",
            "предстоящих гонках \"Гранд При\". Самые известные команды, такие как \n",
            "\"Торнадо\" и \"Динамо\", будут всегда под пристальным вниманием прессы и \n",
            "             ORG───                                                   \n",
            "поклонников автоспорта.\n",
            "Не смотря на требовательные условия гонки, команда \"Стрела\" готова \n",
            "                                                    ORG───         \n",
            "взять на себя испытание и показать своё мастерство в автоспорте. \n",
            "Именно этим занимаются энтузиасты и профессионалы - воплощают свои \n",
            "мечты в жизнь, преодолевая все трудности и преграды в поисках победы.\n",
            "Окончание -\n",
            "Следите за новостями и будьте в курсе всех последних событий в мире \n",
            "автоспорта. Гран при продолжается, и команда \"Стрела\" готова \n",
            "                                              ORG───         \n",
            "выложиться на все 100% ради победы. Не пропустите самые интересные \n",
            "моменты с грядущих гонок и форс-мажорных ситуаций, которые могут \n",
            "кардинально изменить ход соревнования.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = { #чтобы сгрупировать по категориям person, location, organisation, создаю словарь\n",
        "              'PER': [],\n",
        "              'LOC': [],\n",
        "              'ORG': [],\n",
        "}\n",
        "for span in doc.spans: # извлекаю и группирую\n",
        "    categories[span.type].append(span.text)\n",
        "for category, entities in categories.items(): # вывожу категории\n",
        "    print(category)\n",
        "    for entity in entities: # вывожу сущности\n",
        "      print(entity)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjsa2y-WX8Ls",
        "outputId": "ae305bbb-11dd-4ace-ad33-db34665fa884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PER\n",
            "Джон Смит\n",
            "Марк Робинсона\n",
            "Марк\n",
            "Дэвида Харпера\n",
            "LOC\n",
            "Спрингфилд\n",
            "ORG\n",
            "Стрела\n",
            "Стрела\n",
            "АвтоТрек\n",
            "Стрела\n",
            "Стрела\n",
            "Стрела\n",
            "Блиц\n",
            "Стрела\n",
            "Молния\n",
            "Стрела\n",
            "Стрела\n",
            "Динамо\n",
            "Стрела\n",
            "Стрела\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задание 2 из КЛ прошлой домашки, через pymorph2 не получилось, пробую через pandas и наташу\n",
        " from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsSyntaxParser,\n",
        "\n",
        "    Doc\n",
        ")\n"
      ],
      "metadata": {
        "id": "pItNJGonw_hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "def count_stats(text, segmenter, morph_tagger,syntax_parser):\n",
        "  doc = Doc(text)\n",
        "  print('starting segmentation and tagging...')\n",
        "  doc.segment(segmenter)\n",
        "  doc.tag_morph(morph_tagger)\n",
        "  doc.parse_syntax(syntax_parser)\n",
        "  # Теперь есть теги и падежи\n",
        "  print('finished segmentation and tagging')\n",
        "  id2token = {token.id: token for token in doc.tokens}\n",
        "  stats = DataFrame(columns=['text', 'parent_text', 'parent_case'])   # сохраняются все встретившиеся предлоги и информацию о родительских словах\n",
        "  prepositions = set(['в', 'на', 'под', 'за', 'о', 'об', 'перед', 'с', 'со', 'между', 'через', 'меж', 'из-за', 'до', 'для', 'без', 'из-под', 'от', 'по', 'сквозь', 'среди'])\n",
        "  print('start counting...')\n",
        "  for token in doc.tokens:\n",
        "    if token.text.lower() not in prepositions:\n",
        "      continue\n",
        "    parent = id2token.get(token.head_id, None)\n",
        "    if not parent:\n",
        "      continue\n",
        "    stats.loc[len(stats)] = [token.text.lower(), parent.text, parent.feats.get('Case', None)]\n",
        "  print('finished counting')\n",
        "  return stats"
      ],
      "metadata": {
        "id": "v2EPNLf4xXO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('Dama.txt', 'r', encoding = 'utf-8') as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "3on-97Obybme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "syntax_parser = NewsSyntaxParser(emb)\n",
        "\n",
        "stats = count_stats(text, segmenter, morph_tagger, syntax_parser)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOhcAqcqygbU",
        "outputId": "1cb0392b-76f8-45ce-ae81-bc568f4e4125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting segmentation and tagging...\n",
            "finished segmentation and tagging\n",
            "start counting...\n",
            "finished counting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats_without_text = stats.drop(columns='parent_text')\n",
        "stats_without_text.groupby(['text', 'parent_case']).value_counts().to_frame()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lc2W93dPyk58",
        "outputId": "4a3c3eed-6107-4669-b70e-0f6f51bac3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     0\n",
              "text   parent_case    \n",
              "без    Gen           3\n",
              "в      Acc          52\n",
              "       Gen           1\n",
              "       Loc          75\n",
              "       Nom           1\n",
              "для    Gen          10\n",
              "до     Gen           5\n",
              "за     Acc          18\n",
              "       Ins          12\n",
              "       Nom           1\n",
              "из-за  Gen           4\n",
              "       Loc           1\n",
              "из-под Gen           1\n",
              "между  Ins           4\n",
              "на     Acc          38\n",
              "       Loc          10\n",
              "о      Loc           7\n",
              "об     Loc           3\n",
              "от     Acc           1\n",
              "       Gen          11\n",
              "       Par           1\n",
              "перед  Ins           9\n",
              "по     Dat          11\n",
              "под    Acc           2\n",
              "       Ins           5\n",
              "с      Acc           2\n",
              "       Gen           5\n",
              "       Ins          36\n",
              "       Loc           1\n",
              "       Par           1\n",
              "со     Ins           4\n",
              "через  Acc           3\n",
              "       Gen           2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fbc904d-3a75-4f7d-92b3-08cf57cd00ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <th>parent_case</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>без</th>\n",
              "      <th>Gen</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">в</th>\n",
              "      <th>Acc</th>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gen</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loc</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nom</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>для</th>\n",
              "      <th>Gen</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>до</th>\n",
              "      <th>Gen</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">за</th>\n",
              "      <th>Acc</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ins</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nom</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">из-за</th>\n",
              "      <th>Gen</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loc</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>из-под</th>\n",
              "      <th>Gen</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>между</th>\n",
              "      <th>Ins</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">на</th>\n",
              "      <th>Acc</th>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loc</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>о</th>\n",
              "      <th>Loc</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>об</th>\n",
              "      <th>Loc</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">от</th>\n",
              "      <th>Acc</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gen</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Par</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>перед</th>\n",
              "      <th>Ins</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>по</th>\n",
              "      <th>Dat</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">под</th>\n",
              "      <th>Acc</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ins</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">с</th>\n",
              "      <th>Acc</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gen</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ins</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loc</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Par</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>со</th>\n",
              "      <th>Ins</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">через</th>\n",
              "      <th>Acc</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gen</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fbc904d-3a75-4f7d-92b3-08cf57cd00ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1fbc904d-3a75-4f7d-92b3-08cf57cd00ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1fbc904d-3a75-4f7d-92b3-08cf57cd00ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4434ee3f-e117-4142-a439-000db1fafbd9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4434ee3f-e117-4142-a439-000db1fafbd9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4434ee3f-e117-4142-a439-000db1fafbd9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# задание 4\n",
        "! pip install conllu\n",
        "! pip install pandas\n",
        "! pip install ufal.udpipe\n",
        "! pip install pyconll"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN854_xXtdcs",
        "outputId": "2f3564a3-4fa2-4671-8dea-2d25b3bde917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: conllu in /usr/local/lib/python3.10/dist-packages (4.5.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: ufal.udpipe in /usr/local/lib/python3.10/dist-packages (1.3.1.1)\n",
            "Collecting pyconll\n",
            "  Downloading pyconll-3.2.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: pyconll\n",
            "Successfully installed pyconll-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from conllu import parse\n",
        "from pyconll import load_from_file"
      ],
      "metadata": {
        "id": "jwjM7UgUt1IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_from_file(\"ru_gsd-ud-dev.conllu\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YXDBQr9OUxB",
        "outputId": "5e74a052-d616-47e4-b30e-486ac9ddc167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyconll.unit.conll.Conll at 0x7e6d68fdc580>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/UniversalDependencies/UD_Russian-GSD/blob/1df34d56132f5f667348cbce3ef4a3aefa2af7c1/ru_gsd-ud-dev.conllu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agSXbU5fDlQ8",
        "outputId": "8228330c-7c28-4ff7-b5cd-6d46f8ff9029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-24 09:46:46--  https://github.com/UniversalDependencies/UD_Russian-GSD/blob/1df34d56132f5f667348cbce3ef4a3aefa2af7c1/ru_gsd-ud-dev.conllu\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5177 (5.1K) [text/plain]\n",
            "Saving to: ‘ru_gsd-ud-dev.conllu.4’\n",
            "\n",
            "\rru_gsd-ud-dev.conll   0%[                    ]       0  --.-KB/s               \rru_gsd-ud-dev.conll 100%[===================>]   5.06K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-24 09:46:46 (64.7 MB/s) - ‘ru_gsd-ud-dev.conllu.4’ saved [5177/5177]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# В итоге, я запуталась и не до конца понимаю, где ошибка в коде и правильно ли я вообще делаю\n",
        "import conllu\n",
        "class Sentence:\n",
        "  def __init__(self, sent_id, words):\n",
        "    self.sent_id = sent_id\n",
        "    self.words = words\n",
        "  def get_predicatives(self):\n",
        "    predicatives = []\n",
        "    for word in self.words: # проверка на предикатив\n",
        "      if word.form in ['страшно', 'холодно', 'жалко', 'легко', 'понятно', 'важно','интересно', 'понятно']:\n",
        "        predicatives.append((word.form, self.get_dependencies(word))) # добавляю зависимости и предикатив\n",
        "    return predicatives\n",
        "  def get_dependencies(self, token):\n",
        "    dependencies = []\n",
        "    for word in self.words:\n",
        "      if word.head == token.id: # зависимости токена\n",
        "        dependencies.append(word.form)\n",
        "    return dependencies\n",
        "  def analyzer_grammar(file_path, n = 10):\n",
        "    with open('ru_gsd-ud-dev.conllu', 'r', encoding = 'utf-8') as file:\n",
        "      data = file.read()\n",
        "    corpus = conllu.parse(data)\n",
        "    predicatives = []\n",
        "    for sentence_data in corpus:\n",
        "      sentence = Sentence(sentence_data.metadata['sent_id'], sentence_data)\n",
        "# Должен получится список предикатов и зависимостей\n",
        "      sentence_predicatives = sentence.get_predicatives()\n",
        "      predicatives.extend(sentence_predicatives)\n",
        "# Сортирую по частоте\n",
        "    sorted_predicatives = sorted(predicatives, key=lambda x: len(x[1]), reverse=True)\n",
        "    for i in range(min(n, len(sorted_predicatives))):\n",
        "      predicative, dependencies = sorted_predicatives[i]\n",
        "      print('Predicatives:', predicative)\n",
        "      print('Dependencies:', dependencies)\n",
        "analyzer_grammar('ru_gsd-ud-dev.conllu', n=5)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E14dV5DRzvQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Задание 3\n",
        "#ASR (Automatic Speech Recognitison) - это процесс, при котором  речевого сигнал автоматически преобразуется в цифровую информацию.\n",
        "# Алгоритмы распознавания речи основаны на условных вероятностях. Звуки речи состоят из фонем , которые примерно соответствуют отдельным гласным или согласным звукам. Например, алгоритм распознавания речи может решить, что фонема с аналогичной вероятностью может быть либо ‘k’, либо ‘g’.\n",
        "#В настоящее время существует два основных подхода к автоматическому распознаванию речи: традиционный гибридный подход и комплексный подход к обучению.\n",
        "#Традиционный гибридный подход сейчас является устаревшим подходом к распознаванию речи.\n",
        "#К традиционному подходу относятся марковские модели и модели гауссовой смеси, они требуют принудительного выравнивания данных. Принудительное выравнивание - это  получение текстовой транскрипции сегмента звуковой речи и определения того, где во времени встречаются определенные слова в речевом сегменте.\n",
        "#Этот подход сочетает в себе лексическую модель, акустическую модель и языковую модель для предсказания транскрипции.\n",
        "#Комплексный подход к глубокому обучению - это более новый способ управления ASR.\n",
        "# помощью комплексного подхода можно напрямую преобразовать последовательность входных акустических характеристик в последовательность слов. В этом случае данные не нуждаются в принудительном выравнивании.\n",
        "# Самые популярные архитерктуры для распознавания речи в Deep learning -  CTC (Connectionist Temporal Classification) и RNNTs ( Recurrent Neural Network Transducer).\n",
        "# Если говорить про бейзлайн, то как уже упомянулось ранее, Одним из распространенных простых базовых решений является использование гауссовых смесей или скрытых марковских моделей для моделирования акустической последовательности и динамического временного программирования (DTW) для выравнивания и распознавания речи.\n",
        "# Из более современных принято выделять, как уже упоминалось RNN-T,CTC или LSTM (Long Short-term memory) для моделирования акустических признаков.\n",
        "# На данный момент в автоматической распознавании речи успешной моделью является Transformer, так как он показывает высокую точность распознавания и обладает способностью обучаться на больших объемах данных.\n",
        "# Transformer работает следующим образом: модель принимает аудиоспектрограммы в качестве входных данных и предсказывает последовательность символов. Во время обучения декодеру передается целевая последовательность символов, сдвинутая влево, в качестве входных данных. Во время логического вывода декодер использует свои собственные прошлые прогнозы для прогнозирования следующего токена.\n",
        "# Другой популярной моделью является DeepSpeech, она основана на рекуррентных нейронных сетях и обладает отличной производительностью.\n",
        "# DeepSpeech - это механизм преобразования речи в текст (STT) или автоматического распознавания речи (ASR), разработанный Mozilla. Он позволяет распознавать речь и преобразовывать произнесенные слова в текст. DeepSpeech - это основан на глубоком обучении, который использует TensorFlow для реализации.\n",
        "# Если говорить о практическом применении ASR, то здесь следует отметить несколько направлений:\n",
        "# 1) Транскрибирование аудио- и видеозаписей. ASR позволяет автоматически преобразовывать речь на записях в текстовый формат. Это может быть полезно в различных сферах, таких как медицина, судебное делопроизводство, транскрибирование конференций и интервью.\n",
        "# 2) Управление голосовыми интерфейсами. ASR используется для распознавания и интерпретации команд, произносимых пользователями в голосовых интерфейсах, таких как устройства умного дома, голосовые помощники и системы автомобильной навигации.\n",
        "# 3) Телефонный сервис автоматического распознавания. ASR может быть использован для автоматического распознавания речи клиентов в телефонных сервисах, таких как голосовая почта.\n",
        "# 4) Текстовое аннотирование и поиск в медийном контенте. ASR может быть применена для текстового аннотирования и индексации медиа-файлов, таких как аудио- и видеозаписей, для упрощения поиска и доступа к конкретным событиям.\n",
        "# Если же говорить про современные исследования в области ASR, то тут важно выделить несколько направлений:\n",
        "# Во-первых, Transformer, улучшение его производительности в распозновании речи.  Модели позволяют объединить преимущества сверточных и рекуррентных нейронных сетей, а также использовать внимание для обработки последовательностей данных.\n",
        "# Во-вторых, рекуррентные и сверточные нейронные сети, тоже улучшают производительность моделей.\n",
        "# В-третьих, данные, тут исследователи работают над сбором и подготовкой больших объемов данных для обучения моделей ASR. Они также исследуют методы улучшения процесса аугментации данных и их эффективного использования для улучшения моделей.\n"
      ],
      "metadata": {
        "id": "brlLWhoTA1Cw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}