{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Введение в компьютерную лингвистику (задания)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that \n",
      " means comfort. \n",
      " It had a perfectly round door like a porthole, painted green, with a shiny yellow brass knob in the exact middle. The door opened on to a tube-shaped hall like a tunnel: a very comfortable tunnel without smoke, with panelled walls, and floors tiled and carpeted, provided with polished chairs, and lots and lots of pegs for hats and coats - the hobbit was fond of visitors. The tunnel wound on and on, going fairly but not quite straight into the side of the hill - The Hill, as all the people for many miles round called it - and many little round doors opened out of it, first on one side and then on another. \n",
      " No going upstairs for the hobbit: bedrooms, bathrooms, cellars, pantries (lots of these), wardrobes (he had whole rooms devoted to clothes), kitchens, dining-rooms, all were on the same floor, and indeed on the same passage. \n",
      " The best rooms were all on the lefthand side (going in), for these were the only ones to have windows, deep-set round windows looking over his garden, and meadows beyond, sloping down to the river. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Internal: D:\\a\\sentencepiece\\sentencepiece\\src\\trainer_interface.cc(661) [(trainer_spec_.vocab_size()) == (model_proto->pieces_size())] Vocabulary size too high (400). Please set it to a value <= 178.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\task1semestr\\CL.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/task1semestr/CL.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   text \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/task1semestr/CL.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# В данном кусочке кода обучается BPE модель на тексте\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/task1semestr/CL.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m spm\u001b[39m.\u001b[39;49mSentencePieceTrainer\u001b[39m.\u001b[39;49mtrain(\u001b[39m'\u001b[39;49m\u001b[39m--input=text_1.txt --model_prefix=bpe_model --vocab_size=400\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/task1semestr/CL.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Потом загружается созданный BPE модель\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/task1semestr/CL.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m bpe \u001b[39m=\u001b[39m spm\u001b[39m.\u001b[39mSentencePieceProcessor()\n",
      "File \u001b[1;32mc:\\Python\\lib\\site-packages\\sentencepiece\\__init__.py:989\u001b[0m, in \u001b[0;36mSentencePieceTrainer.Train\u001b[1;34m(arg, logstream, **kwargs)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    987\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTrain\u001b[39m(arg\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, logstream\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    988\u001b[0m   \u001b[39mwith\u001b[39;00m _LogStream(ostream\u001b[39m=\u001b[39mlogstream):\n\u001b[1;32m--> 989\u001b[0m     SentencePieceTrainer\u001b[39m.\u001b[39m_Train(arg\u001b[39m=\u001b[39marg, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python\\lib\\site-packages\\sentencepiece\\__init__.py:945\u001b[0m, in \u001b[0;36mSentencePieceTrainer._Train\u001b[1;34m(arg, **kwargs)\u001b[0m\n\u001b[0;32m    943\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Train Sentencepiece model. Accept both kwargs and legacy string arg.\"\"\"\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[39mif\u001b[39;00m arg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(arg) \u001b[39mis\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[1;32m--> 945\u001b[0m   \u001b[39mreturn\u001b[39;00m SentencePieceTrainer\u001b[39m.\u001b[39;49m_TrainFromString(arg)\n\u001b[0;32m    947\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_encode\u001b[39m(value):\n\u001b[0;32m    948\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Encode value to CSV..\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python\\lib\\site-packages\\sentencepiece\\__init__.py:923\u001b[0m, in \u001b[0;36mSentencePieceTrainer._TrainFromString\u001b[1;34m(arg)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    922\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_TrainFromString\u001b[39m(arg):\n\u001b[1;32m--> 923\u001b[0m     \u001b[39mreturn\u001b[39;00m _sentencepiece\u001b[39m.\u001b[39;49mSentencePieceTrainer__TrainFromString(arg)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Internal: D:\\a\\sentencepiece\\sentencepiece\\src\\trainer_interface.cc(661) [(trainer_spec_.vocab_size()) == (model_proto->pieces_size())] Vocabulary size too high (400). Please set it to a value <= 178."
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece # задание 1 для начала нужно установить библиотеку sentencepiece. (SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training.)\n",
    "import sentencepiece as spm #Training is performed by passing parameters of spm\n",
    "\n",
    "# Читаем текст из файла\n",
    "with open('text_1.txt', 'r', encoding='Utf-8') as f: # Windows стандартной кодировкой является cp1252\n",
    "  print(*f) # вывожу содержимое файла\n",
    "  text = f.read()\n",
    "\n",
    "# В данном кусочке кода обучается BPE модель на тексте\n",
    "spm.SentencePieceTrainer.train('--input=text_1.txt --model_prefix=bpe_model --vocab_size=400')\n",
    "\n",
    "# Потом загружается созданный BPE модель\n",
    "bpe = spm.SentencePieceProcessor()\n",
    "bpe.load('bpe_model.model')\n",
    "\n",
    "# Получаем список всех токенов в тексте\n",
    "tokens = bpe.EncodeAsPieces(text)\n",
    "\n",
    "# Печатаю первые 400 токенов\n",
    "if len(tokens) <= 400:\n",
    "  print(tokens)\n",
    "else:\n",
    "  print(tokens[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3\n",
    "# 1) [a-zA-Z0-9_.-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+ # задание 3, пункт 1\n",
    "# 2) ^([a-zA-Z]:\\\\?|\\\\)([\\w.-]+\\/)*([\\w.-]+)\\.([\\w.-]+)$  # задание 3, пункт 2\n",
    "# 3) \\[\\[([^\\[\\]]*):([^\\[\\]]*):([^\\[\\]]*):([^\\[\\]]*)\\] # задание 3, пункт 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2 сделала вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Питон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human: #задание 1, семинар 6\n",
    "  def __init__(self, age):\n",
    "    self.age = age\n",
    "  def __bool__(self):\n",
    "    return self.age >= 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "person = Human(18)\n",
    "print(bool(person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep # задача 2, семинар 6\n",
    "class Linguist:\n",
    "  def __init__(self, name, affiliation, stamina, publications = []): # для себя пишу: self - это способ обратиться к конкретному экземпляру\n",
    "    self.name = name\n",
    "    self.affiliation = affiliation\n",
    "    self.stamina = stamina\n",
    "    self.publications = publications # список публикации\n",
    "  def __str__(self):\n",
    "    return f\"Linguist: {self.name} from {self.affliation}\"\n",
    "  def __repr__(self):\n",
    "    return f\"Linguist('{self.name}', '{self.affliation}', {self.stamina}, {self.publications})\"\n",
    "  def work(self, publication):\n",
    "    n = len(publication) # нужно вычислить время на основе названия публикации\n",
    "    k = 1  # коэффициент выносливости\n",
    "    tiredness = k * n  # тогда значение  усталости будет представлено следующим образом\n",
    "    if tiredness > self.stamina:\n",
    "          self.stamina = 0\n",
    "    else:\n",
    "          self.stamina -= tiredness\n",
    "  def sleep(self, hours):\n",
    "        n = hours  # нужно вычислить показатель времени на основе количества часов сна\n",
    "        k = 1  # коэффициент выносливости\n",
    "        stamina_recover = k * n  # тогда для того, чтобы вычислить значение восстановления выносливости, нужно выносливость умножить на n\n",
    "        self.stamina += stamina_recover\n",
    "  def show_publications(self):\n",
    "        if len(self.publications) > 0:\n",
    "            print(f\"Linguist {self.name} имеет следующие публикации:\")\n",
    "            for publication in self.publications:\n",
    "                print(publication)\n",
    "        else:\n",
    "            print(f\"Linguist {self.name} еще не имеет публикаций.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguist Вася Сидоров еще не имеет публикаций.\n"
     ]
    }
   ],
   "source": [
    "linguist = Linguist(\"Вася Сидоров\", \"Университет МАИ\", 10)\n",
    "publication1 = \"Работа 1\"\n",
    "publication2 = \"Работа 2\"\n",
    "linguist.work(publication1)\n",
    "linguist.work(publication2)\n",
    "linguist.show_publications()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lunch: # домашняя работа №2, урок 6\n",
    "  def __init__(self):\n",
    "    self.customer = Customer() # создаю с () новый объект класса Customer и присваиваю его значение атрибуту self.customer\n",
    "    self.employee = Employee() # тоже самое делаю с Employee\n",
    "  def order(self, foodName):\n",
    "    self.customer.placeOrder(foodName, self.employee) # я вызываю метод placeOrder() у объекта customer, который является атрибутом класса\n",
    "  def result(self):\n",
    "    self.customer.printFood() # метод pringFood выведет информацию о заказанной еде\n",
    "\n",
    "class Customer:\n",
    "  def __init__(self):\n",
    "    self.food = None\n",
    "  def placeOrder(self, foodName, employee): # этот метод будет использоваться для размещения заказа на еду\n",
    "    self.food = employee.cookOrder(foodName) # вызов метода cookOrder объекта employee (класса Employee)\n",
    "  def printFood(self): # будет использоваться для вывода информации о заказанной еде (class Customer)\n",
    "    if self.food: # если ли есть, то выведется информация по заказу\n",
    "      print(\"Food:\", self.food.name)\n",
    "    else:\n",
    "      print(\"Food isn't ordered\")\n",
    "\n",
    "class Employee:\n",
    "  def cookOrder(self, foodName): # метод для приготовления еды\n",
    "    return Food(foodName)\n",
    "\n",
    "class Food:\n",
    "  def __init__(self, name):\n",
    "    self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food: Mushroom pizza\n"
     ]
    }
   ],
   "source": [
    "lunch = Lunch()\n",
    "lunch.order(\"Mushroom pizza\")\n",
    "lunch.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задача 3 \"Тамагочи\" # недоделанная, но хотелось бы доделать позже, так как интересная задачка\n",
    "from random import randrange # вместо того, чтобы постоянно не писать random.randrange\n",
    "\n",
    "class Pet(object):\n",
    "  '''A virtual pet'''\n",
    "  excitement_reduce = 3\n",
    "  excitement_max = 10\n",
    "  excitement_warning = 3  # все характеристики к питомцу\n",
    "  food_reduce = 2\n",
    "  food_max = 10\n",
    "  food_warning = 3\n",
    "  vocabulary = ['\"Gr...\"']\n",
    "  def __init__(self, name, animal_type):\n",
    "    self.name = name\n",
    "    self.animal_type = animal_type\n",
    "    self.food = randrange(self.food_max)\n",
    "    self.excitement = randrange(self.excitement_max)\n",
    "    self.vocabulary = self.vocabulary[:] # : с помощью этого добавляем то, что внутри [Gr....]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
